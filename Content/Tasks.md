## Task

### Image Processing and Generation
1. **Image Generation**
2. **Image Segmentation**
3. **Image Classification**
4. **Image Restoration**
5. **Image-to-Image Translation**
6. **Super-Resolution**
7. **Denoising**
8. **Instance Segmentation**
9. **Object Detection**
10. **Medical Image Segmentation**
11. **Semantic Segmentation**

### Language Modelling and Text Processing
1. **Language Modelling**
2. **Text-to-Image Generation**
3. **Text Generation**
4. **Question Answering**
5. **Sentence**
6. **Retrieval**
7. **RAG (Retrieval-Augmented Generation)**
8. **Decision Making**
9. **Large Language Model**
10. **Few-Shot Learning**

### Learning and Adaptation
1. **Self-Supervised Learning**
2. **Classification**
3. **Unsupervised Domain Adaptation**
4. **Domain Adaptation**

### Specialized Applications
1. **Video Generation**
2. **Activity Recognition**
3. **Human Activity Recognition**
4. **Autonomous Driving**
5. **Pedestrian Detection**

### Efficiency and Benchmarking
1. **Computational Efficiency**
2. **Benchmarking**
3. **Management**



## Learning Paradigms

### Supervised Learning
1. **Traditional Supervised Learning**
   - Training with fully labeled data.
2. **Semi-Supervised Learning**
   - Training with a mix of labeled and unlabeled data.
3. **Weakly-Supervised Learning**
   - Training with imprecise, limited, or noisy labels.
4. **Self-Supervised Learning**
   - Generating labels from the data itself for pretext tasks.

### Unsupervised Learning
1. **Traditional Unsupervised Learning**
   - Training with no labeled data.
2. **Clustering**
   - Grouping similar data points together.
3. **Dimensionality Reduction**
   - Reducing the number of random variables under consideration.
4. **Generative Models**
   - Learning to generate new data points from the same distribution as the training set.
   
### Reinforcement Learning
1. **Model-Free Reinforcement Learning**
   - Learning policies directly from interactions with the environment.
2. **Model-Based Reinforcement Learning**
   - Learning a model of the environment and planning using this model.
3. **Deep Reinforcement Learning**
   - Using neural networks as function approximators in reinforcement learning.

### Transfer Learning
1. **Domain Adaptation**
   - Transferring knowledge from one domain to another.
2. **Multi-Task Learning**
   - Learning multiple tasks simultaneously.
3. **Meta-Learning**
   - Learning to learn across different tasks.

### Few-Shot Learning
1. **One-Shot Learning**
   - Learning information about object categories from one, or only a few, training images.
2. **Zero-Shot Learning**
   - Predicting classes that were not seen during training.

### Active Learning
1. **Pool-Based Sampling**
   - Selecting the most informative data points from a pool of unlabeled data.
2. **Stream-Based Sampling**
   - Making decisions on each data point as it arrives.

### Online Learning
1. **Incremental Learning**
   - Continuously updating the model as new data comes in.
2. **Adaptive Learning**
   - Adapting the learning rate or other hyperparameters in response to the data.

### Collaborative Learning
1. **Federated Learning**
   - Training models collaboratively across multiple devices while keeping data localized.
2. **Ensemble Learning**
   - Combining multiple models to improve performance.

### Other Paradigms
1. **Self-Training**
   - Using a model's predictions to iteratively label unlabeled data.
2. **Curriculum Learning**
   - Training models starting from easy examples and gradually increasing difficulty.
3. **Contrastive Learning**
   - Learning by comparing similar and dissimilar pairs of data points.

